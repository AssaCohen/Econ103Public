\documentclass[addpoints,12pt]{exam}
\usepackage{amsmath, amssymb}
\linespread{1.1}
\usepackage{hyperref}
\usepackage{enumerate}


%To include the answers use:
%	pdflatex "\def\showanswers{1} \input{thisfile.tex}"
\ifdefined\showanswers
  \printanswers
\else
  \noprintanswers
\fi

\title{Problem Set \#4}
\author{Econ 103}
\date{}
\begin{document}
\maketitle

\section*{Part I -- Problems from the Textbook}
Chapter 3: 1, 3, 5, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29

% \section*{Part II -- R Tutorial}
% No R Tutorial this week.

\section*{Part II -- Additional Problems}
\begin{questions}

\question Suppose you flip a fair coin twice.
	\begin{parts}
		\part List all the basic outcomes in the sample space.
		\begin{solution}
			$S = \{HH, HT, TT, TH\}$
		\end{solution}
		\part Let $A$ be the event that you get at least one head. List all the basic outcomes in $A$.
		\begin{solution}
			$A = \{HH, HT, TH\}$
		\end{solution}
		\part What is the probability of $A$?
		\begin{solution}
			$P(A) = 3/4 = 0.75$
		\end{solution}
		\part List all the basic outcomes in $A^c$. 
		\begin{solution}
			$A^c = \{TT\}$
		\end{solution}
		\part What is the probability of $A^c$?
		\begin{solution}
			$P(A^c) = 1/4$
		\end{solution}
	\end{parts}

\question Suppose I deal two cards at random from a well-shuffled deck of 52 playing cards. What is the probability that I get a pair of aces? 
	\begin{solution}
	You can either solve this assuming that order doesn't matter:
		$$\frac{\binom{4}{2}}{\binom{52}{2}} = \frac{4!/(2!\times 2!)}{52!/(50!  \times 2!)} = \frac{6}{(52\times 51)/2}= 6/1326 = 1/221$$
		or that it does:
		$$\frac{P^4_2}{P^{52}_2} = \frac{4!/2!}{52!/50!} =\frac{(4\times 3)}{(52\times 51)} = 12/2652 = 1/221$$
		In either case, the answer is the same: $1/221  \approx 0.005$
	\end{solution}

\question Suppose everyone in a class of one hundred students flips a fair coin five times.
	\begin{parts}
		\part What is the probability that John Smith, a particular student in the class, gets five heads in a row? 
			\begin{solution}
				$(1/2)^5 = 1/32\approx 0.03$
			\end{solution}
	 	\part What is the probability that at least one person gets five heads in a row?
	 	\begin{solution}
	 	Use the complement rule: let $A$ be the event that at least one person gets five heads in a row. Calculate the probability that no one gets 5 heads in a row as follows:
	 		$$P(A^c) = (1 - 1/2^5)^{100} = (31/32)^{100}\approx 0.04$$
	 		Hence the desired probability is about $0.96$.
	 	\end{solution}
	\end{parts}

\question (Adapted from Mosteller, 1965) A jury has three members: the first flips a coin for each decision, and each of the remaining two independently has probability $p$ of reaching the correct decision. Call these two the ``serious'' jurors and the other the ``flippant'' juror (pun intended).
	\begin{parts}
		\part What is the probability that the serious jurors both reach the same decision?
			\begin{solution}
				There are two ways for them to agree: they can either make the right decision, $p^2$, or the wrong decision, $(1-p)^2$. These are mutually exclusive, so we sum the probabilities for a total of $p^2 + (1-p)^2$
			\end{solution}
		\part What is the probability that the serious jurors each reach different decisions?
			\begin{solution}
			There are two ways for them to disagree: either the first makes the wrong decision, $p(1-p)$, or the second makes the wrong decision, $(1-p)p$. These are mutually exclusive, so we sum the probabilities for a total of $2p(1-p)$.
			\end{solution}
	\part What is the probability that the jury reaches the correct decision? Majority rules.
	\begin{solution}
	 With probability $p^2$ the serious jurors agree and make the correct decision so the flippant juror is irrelevant. With probability $2p(1-p)$ they disagree. In half of these cases the flippant juror makes the correct decision. Thus, the overall probability is $p^2 + p(1-p) = p$.
	\end{solution}
	\end{parts}

\question This question refers to the prediction market example from lecture. Imagine it is October 2012. Let $O$ be a contract paying \$10 if Obama wins the election, zero otherwise, and $R$ be a contract paying \$10 if Romney wins the election, zero otherwise. Let $\mbox{Price}(O)$ and $\mbox{Price}(R)$ be the respective prices of these contracts.
	\begin{parts}
	\part Suppose you \emph{buy} one of each contract. What is your profit?
		\begin{solution}
			Regardless of whether Romney or Obama wins, you get \$10. Thus, your profit is $$10 - \mbox{Price}(O) - \mbox{Price}(R)$$
		\end{solution}
	\part Suppose you \emph{sell} one of each contract. What is your profit?
		\begin{solution}
			Regardless of whether Romney or Obama wins, you have to pay out \$10. Thus, your profit is $$\mbox{Price}(O) + \mbox{Price}(R) - 10$$
		\end{solution}
	 \part What must be true about $\mbox{Price}(O)$ and $\mbox{Price}(R)$, to prevent an opportunity for statistical arbitrage? 
	 \begin{solution}
	  From (a) we see that you can earn a guaranteed, risk-free profit from \emph{buying} one of each contract whenever $10 > \mbox{Price}(O) +\mbox{Price}(R)$. From (b) we see that you can earn a guaranteeed, risk-free profit by \emph{selling} one of each contract whenever $ \mbox{Price}(O) +\mbox{Price}(R) > 10$. Therefore, the only way to prevent statistical arbitrage is to have $\mbox{Price}(O) +\mbox{Price}(R) = 10$.
	 \end{solution}
	 \part How is your answer to part (c) related to the Complement Rule?
	 	\begin{solution}
	 	In class we discussed how the market price of a prediction contract can be viewed as a subjective probability assessment. To find the implied probability we divide the price of the contract by the amount that is pays out, in this case \$10. Hence, dividing through by \$10, we see that the condition from part (b) when stated in probability terms is
	 	$$P(O) = 1 - P(R)$$
	 	This is precisely the Complement Rule because $R = O^c$.
	 	\end{solution}
	 \part What is the implicit assumption needed for your answers to parts (a)--(c) to be correct? How would your answers change if we were to relax this assumption?
	 	\begin{solution}
	 	The above discussion assumes that the only possible outcomes are Obama or Romney winning the election, that is $O \cup R = S$. This is equivalent to assuming that the probability of a third-party candidate winning the election is zero. If this assumption is not true, we need to redo the above with an extra contract. Let $I$ be a contract that pays out \$10 if a third-party (i.e.\ independent) candidate wins the election, zero otherwise. Then the answers to the above become:
	 		\begin{enumerate}[(a)]
	 			\item $10 - \mbox{Price}(O) - \mbox{Price}(R) -\mbox{Price}(I) $
	 			\item  $\mbox{Price}(O) + \mbox{Price}(R) +\mbox{Price}(I) - 10$
	 			\item $\mbox{Price}(O) + \mbox{Price}(R) +\mbox{Price}(I) = 10$
	 			\item The Complement Rule becomes:
	 				$$P(I) = 1 - P(O) - P(R)$$
	 		\end{enumerate}
	 	\end{solution}
	 \end{parts}
	 


\question ``Odd Question'' \# 6, from Hacking (2001):
	\begin{quote}You are a physician. You think it is quite likely that one of your patients has strep throat, but you aren't sure. You take some swabs from the throat and send them to a lab for testing. The test is (like nearly all lab tests) not perfect. If the patient has strep throat, then 70\% if the time the lab says yes. But 30\% of the time it says NO. If the patient does not have strep throat, then 90\% of the time the lab says NO. But 10\% of the time it says YES. You send five successive swabs to the lab, from the same patient. and get back these results in order: YES, NO, YES, NO, YES.\end{quote} 
	Let $S$ be the event that the patient has strep throat, and $S^c$ be the even that she does not. Let $Y$ be the event that a given test says YES and $N = Y^c$ be the event that a given test says NO. You may assume that the tests are independent.

	\begin{parts}
		\part Calculate the probability that your patient has strep throat. (Hint, there is a missing piece of information and you should express your answer \emph{in terms of it}.)
	\begin{solution}
		 The probabilities from the question statement are:
			\begin{eqnarray*}
				P(Y|S) &=& 0.7\\
				P(N|S) &=& 0.3\\
				P(Y|S^c) &=&0.1\\
				P(N|S^c) &=&0.9
			\end{eqnarray*}
We are asked to calculate $P(S|YNYNY)$ where $YNYNY$ denotes the sequence of outcomes YES, NO, YES, NO, YES \emph{in that order} from the fives tests. By Bayes' Rule,
	$$P(S|YNYNY) = \frac{P(YNYNY|S)P(S)}{P(YNYNY)}$$
	From the information provided above, we can calculate everything \emph{except} the base rate, so we will express everything in terms of $P(S)$. By independence, 
		\begin{eqnarray*}
			P(YNYNY|S) &=& P(Y|S) \times P(N|S) \times P(Y|S) \times P(N|S) \times P(Y|S)\\
			&=& P(Y|S)^3 \times P(N|S)^2 = (7/10)^3 \times (3/10)^2\\
			&=& 343/1000 \times 9/100 
		\end{eqnarray*}
		and similarly,
				\begin{eqnarray*}
			P(YNYNY|S^c) &=& P(Y|S^c) \times P(N|S^c) \times P(Y|S^c) \times P(N|S^c) \times P(Y|S^c)\\
			&=& P(Y|S^c)^3 \times P(N|S^c)^2 = (1/10)^3 \times (9/10)^2\\
			&=& 1/1000 \times 81/100 
		\end{eqnarray*}
		Now, by the law of total probability,
		\begin{eqnarray*}
			P(YNYNY) &=& P(YNYNY|S)P(S) + P(YNYNY|S^c)P(S^c)\\
			&=& P(YNYNY|S) \times P(S) + P(YNYNY|S^c) \times (1-P(S))\\
			&=& 343/1000 \times 9/100 \times P(S)\\&& + 1/1000 \times 81/100 \times (1-P(S))
		\end{eqnarray*}
		Therefore, multiplying the numerator and denominator by $10^5$
		\begin{eqnarray*}
			P(S|YNYNY) &=&\frac{P(YNYNY|S)P(S)}{P(YNYNY)}\\
				&=& \frac{343 \times 9 \times P(S)}{343 \times 9 \times P(S) + 81 \times (1-P(S))}\\
				&=& \frac{3087 P(S)}{3087 P(S) + 81 - 81P(S)}\\
				&=& \frac{3087 P(S)}{3006 P(S) + 81}\\
				&=& \frac{3087}{3006 + 81/P(S)}
		\end{eqnarray*}
	\end{solution}
	\part Based on your answer to part (b) do you think the patient has strep throat? Explain.
		\begin{solution}
			Since we don't know the base rate $P(S)$ we can't get an explicit value for the conditional probability from part (a). One way forward would be to ask what bounds on $P(S)$ would ensure that $P(S|YNYNY) > 1/2$. To do this, we solve the following expression for $P(S)$:
				\begin{eqnarray*}
					\frac{1}{2} &=& \frac{3087}{3006 + 81/P(S)}\\
					3006 + 81/P(S)&=& 6174\\
					6174 P(S) &=& 3006 P(S) + 81\\
					3168 P(S) &=& 81\\
					P(S) &=& 81/3168 \approx 0.026
				\end{eqnarray*}
				Therefore, as long as $P(S) > 0.026$, the test results given above make it more likely than not that our patient has strep throat. But where does this leave us? How can we evaluate whether this restriction on the base rate is likely to be satisfied? In this example the term ``base rate'' is perhaps a little misleading as the relevant probability $P(S)$  is \emph{not} the overall rate of strep throat in the population. A better term in this case would be ``prior probability.'' That is, how likely is it \emph{before we see that test results} that this patient has strep throat? The question statement says that you, the physician, think it is ``quite likely'' that the patient has strep throat, presumably based on her symptoms, etc. Perhaps ``quite likely'' should be interpreted as $P(S) = 0.9$, in which case $P(S|YNYNY) \approx 0.997$. I would certainly interpret ``quite likely'' as $P(S)>1/2$ and if $P(S) = 1/2$, we have $P(S|YNYNY) \approx 0.974$. The following is a reasonable summary of our results. If you have \emph{any reason to believe} a priori that your patient has strep throat, these test results imply that it is \emph{extremely likely} she does. However, if you were to randomly test someone off the street who had no symptoms of strep throat and get the above results, the evidence would be much less convincing. I would doubt, for example, that more than 2.6\% of the population have strep throat at any given time, as would be required to make the conditional probability greater than 1/2.
				

		\end{solution}
\end{parts}


 
\section*{Part III -- ``Challenge'' Problems}
These are optional. If you're up for a challenge you'll learn quite a bit from these.


\question (Adapted from Mosteller, 1965) ``What is the least number of persons required if the probability exceeds 1/2 that two or more of then have the same birthday? (Year of birth need not match).''
	[Hint: Use the Complement Rule.]
	\begin{solution}
If there are $N$ people, then there are $365 \times 365 \times \cdots 365 = 365^N$ possible assignments of people to birthdays. If we impose the restriction that no pair of individuals shares a birthday, then there are 365 ways to choose the first person's birthday, 364 ways to choose the second person's birthday, and so on. Altogether, there are $365!/(365 - N)!$ ways for $N$ people to all have different birthdays. Assuming that each assignment of people to birthdays is equally likely, the probability that no pair shares a birthday is:
		$$\frac{365!}{(365 - N)!} \cdot \frac{1}{365^N}$$
Therefore, by the complement rule, the probability that \emph{at least one pair} of people shares a birthday is
	$$1 - \frac{365!}{(365 - N)!} \cdot \frac{1}{365^N}$$
We can't evaluate this expression as is because the factorials involved are too big for a computer to handle. An equivalent way to write the expression is:
	$$1 - \frac{365 \cdot 364 \cdots \left(365 - N + 1\right)}{365^N}$$
We could evaluate this in R as follows
\begin{verbatim}
N <- 23
numerator <- prod(seq(from = (365 - N + 1), to = 365))
denominator <- 365^N
1 - (numerator/denominator)
	\end{verbatim}
Trying different values for $N$,
	\begin{center}
	\begin{tabular}{cc}
	$N$ & Prob.\\
	\hline
22   &  0.4757\\
23   &  0.5073\\
24   &  0.5383
	\end{tabular}
	\end{center}
so the answer is 23 people.
	\end{solution}
	
\question Formally prove the Addition Rule: $P(A \cup B) = P(A) + P(B) - P(A \cap B)$ using the basic notions of set theory we learned in class and the axioms of probability. [Hint: Try to translate the intution from the Venn diagram into an equation.]
	\begin{solution}
		First, notice from the Venn diagram shown in class that we can partition $A\cup B$ into three mutually exclusive pieces: everything in $A$ that is \emph{not} in $B$, namely $A \cap B^c$,  everything in $B$ that is \emph{not} in $A$, namely $B \cap A^c$, and everything that is in \emph{both} $A$ and $B$, namely $A\cap B$. Writing this formally using our set theory notation:
		$$A \cup B = (A \cap B^c) \cup (B \cap A^c) \cup (A\cap B)$$
			where
			\begin{eqnarray*}
				(A \cap B^c) \cap (B \cap A^c)= \emptyset\\
				(A \cap B^c) \cap (A\cap B)= \emptyset\\
				(B \cap A^c) \cap (A\cap B) = \emptyset
			\end{eqnarray*}
		Now we can use two facts about probability. First, if two events are logically equivalent (contain exactly the same basic outcomes) then they have the same probability:
		$$P(A \cup B) = P\left[(A \cap B^c) \cup (B \cap A^c) \cup (A\cap B)\right]$$
Second, the probabilities of mutually exclusive events sum:
		$$P\left[(A \cap B^c) \cup (B \cap A^c) \cup (A\cap B)\right] = P(A \cap B^c) + P(B \cap A^c) + P(A\cap B)$$
Combining these two equations:
		$$P(A \cup B) = P(A \cap B^c) + P(B \cap A^c) + P(A\cap B)$$
		Now we're almost done. We want $P(A)$ rather than $P(A \cap B^c)$ and $P(B)$ rather than $P(B \cap A^c) $ on the right hand side of the equation. We also want a minus rather than a plus in front of $P(A\cap B)$. Just as we partitioned $A\cup B$ into mutually exclusive pieces, we can partition both $A$ and $B$ into mutually exclusive pieces as follows:
		\begin{eqnarray*}
			A &=& (A\cap B^c) \cup (A \cap B)\\
			B &=& (B\cap A^c) \cup (B \cap A)
		\end{eqnarray*}
And again using the fact that the probabilities of equivalent events are equal and the fact that the probabilities of mutually exclusive events sum,
		\begin{eqnarray*}
			P(A) &=& P(A\cap B^c) + P(A \cap B)\\
			P(B) &=& P(B\cap A^c) + P(A \cap B)
		\end{eqnarray*}
Rearranging, 
		\begin{eqnarray*}
			P(A\cap B^c)  &=&P(A) - P(A \cap B)\\
			P(B\cap A^c) &=& P(B)  - P(A \cap B)
		\end{eqnarray*}
Finally, substituting these two equations into our expression for $P(A\cup B)$ from above
	\begin{eqnarray*}
	P(A \cup B) &=& P(A \cap B^c) + P(B \cap A^c) + P(A\cap B)\\
	&=& \left[P(A) - P(A \cap B)\right] + \left[P(B)  - P(A \cap B)\right] + P(A\cap B)\\
	&=& P(A) + P(B) - P(A \cap B)
	\end{eqnarray*}
		\end{solution}


\question Weren't stumped by the Monte Hall problem? Try this example from Mosteller (1965):
	\begin{quote}
	Three prisoners, $A$, $B$, and $C$, with apparently equally good records have applied for parole. The parole board has decided to release two of the three, and the prisoners know this but not which two. A warder friend of prisoner A knows who are to be released. Prisoner A realizes that it would be unethical to ask the warder if he, A, is to be released, but thinks of asking for the name of \emph{one} prisoner \emph{other than himself} who is to be released. He thinks that before he asks, his chances of release are 2/3. He thinks that if the warder says ``$B$ will be released,'' his own chances have now gone down to 1/2, because either $A$ and $B$ or $B$ and $C$ are to be released. And so $A$ decides not to reduce his chances by asking. However, $A$ is mistaken in his calculations. Explain.
	\end{quote}
	\begin{solution}
		From Mosteller (1965):
			\begin{quote}
				The trouble with $A$'s argument is that he has not listed the possible events properly. In technical jargon, he does not have the correct sample space. He thinks his experiment has three possible outcomes: $AB$, $AC$, $BC$ with equal probabilities of $\frac{1}{3}$. From his point of view, that is the correct sample space for the experiment conducted by the parole board given that they are to release two of the three. But $A$'s own experiment adds an event--the reponse of the warder. The outcomes of his proposed experiment and reasonable probabilities for them are:
				\begin{enumerate}
					\item $A$ and $B$ released and warder says $B$, probability $\frac{1}{3}$
					\item $A$ and $C$ released and warder says $C$, probability $\frac{1}{3}$
					\item $B$ and $C$ released and warder says $B$, probability $\frac{1}{6}$
					\item $B$ and $C$ released and warder says $C$, probability $\frac{1}{6}$
				\end{enumerate}
		If, in reponse to $A$'s question, the warder says ``$B$ will be released,'' then the probability for $A$'s release is the probability from outcome 1 divided by the sum of the probabilities from outcomes 1 and 3. Thus, the final probability of $A$'s release is $\frac{1}{3}/\left(\frac{1}{3} + \frac{1}{6}\right)$, or $\frac{2}{3}$, and mathematics comes round to common sense after all.
			\end{quote}
	Because this is such a tricky example, a bit more elaboration may be in order. If $A$ is to be released, the warder's hands are tied. Since he cannot tell $A$ that $A$ will be released, he \emph{must} name the other man who is to be released: $B$ in outcome 1, and $C$ in outcome 2. Since the warder has no influence in these two cases, their probabilities are equal to the initial probabilities from the parole board: $\frac{1}{3}$ each. The complication arises from the case where $A$ is \emph{not} to be released. The probability that we are in this situation is $\frac{1}{3}$ and here the warder has a choice: he can either say that $B$ will be released or $C$ will be released. To calculate the probabilities of outcomes 3 and 4 we need to know the probability of each choice the warder could make. The solution provided by Mosteller assumes that, in the situation where he has to make a choice, the warder simply flips a coin. Thus the probability of each of the outcomes 3 and 4 is $\frac{1}{2} \times \frac{1}{3} = \frac{1}{6}$. 
	
	But why is this a reasonable assumption? One way to think about this would be to ask what rule the warder should follow to \emph{ensure} that his answer does not provide $A$ with any additional information. To make this more precise, suppose that in cases 3 and 4 the warder follows the rule ``say $B$ with probability $p$.'' When $p=1$ we'll take this to mean ``always say $B$'' and when $p=0$ we'll take this to mean ``always say $C$.'' Then, redoing the conditional probability calculation from above with $p$ in place of $\frac{1}{2}$, we find that the conditional probability that $A$ is to be released given that the warder says $B$ is 
	$$\frac{1/3}{1/3 + p \cdot 1/3} = \frac{1/3}{(1+p)/3} = \frac{1}{1+p}$$
The condition that the warder provide no additional information is equivalent to requiring that this condition probability of $A$'s release be equal to the unconditional probability of his release, $2/3$. Solving for $p$,
	\begin{eqnarray*}
		\frac{2}{3} &=& \frac{1}{1+p}\\
		2(1+p) &=& 3\\
		2 + 2p &=& 3\\
		2p &=& 1\\
		p&=& 1/2
	\end{eqnarray*}
Thus we have what is essentially a game-theoretic justification for Mosteller's assumption (c.f.\ \emph{mixed equilibrium strategy} in any game theory textbook).
	\end{solution}
\end{questions}






\end{document}