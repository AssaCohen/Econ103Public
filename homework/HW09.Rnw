\documentclass[addpoints,12pt]{exam}
\usepackage{amsmath, amssymb}
\linespread{1.1}
\usepackage{hyperref}
\usepackage{enumerate}
\usepackage{multirow}


\newcommand{\p}{\mathbb{P}}
\newcommand{\expect}{\mathbb{E}}
\newcommand{\var}{\mathbb{V}}
\newcommand{\cov}{Cov}
\newcommand{\slfrac}[2]{\left.#1\right/#2}




%-------------------DON'T CHANGE---------------------%
%The following is needed to prevent a conflict between knitr and the exam class involving the package ``framed.''
<<cache=FALSE,include=FALSE,purl=FALSE>>= 
knit_hooks$set(document=function(x){ 
  sub('\\usepackage{framed}', '', x, fixed=TRUE) 
}) 
@ 


%This keeps images from being too big, centers them, and makes sure we use pdf images
<<cache=FALSE,include=FALSE,purl=FALSE>>= 
opts_chunk$set(fig.width=4, fig.height=4, fig.align='center',dev='pdf')
@


%Change the default width of the output to fit within the solution boxes
<<cache=FALSE,include=FALSE,purl=FALSE>>= 
options(width = 60)
@
%-------------------DON'T CHANGE---------------------%


%To include the answers use:
%  pdflatex "\def\showanswers{1} \input{thisfile.tex}"
\ifdefined\showanswers
  \printanswers
\else
  \noprintanswers
\fi

\title{Problem Set \#9}
\author{Econ 103}
\date{}
\begin{document}
\maketitle




\noindent For all of the questions on this assignment, assume the data are a random sample from a normal population, that is $X_1, \hdots, X_n \sim \mbox{iid } N(\mu, \sigma^2)$. Depending on the specifics of the question, $\sigma$ may be known or unknown. I'd recommend that you use R for any problems in which you need to calculate sample means or variances from a dataset: in an exam, I wouldn't make you do this by hand.

\section*{Part I -- Problems from the Textbook}
Chapter 8: 1, 3, 5, 7, 9

\vspace{1em}
\noindent To avoid typing, you can download the data for question 8-9 from my website and import it directly into R with the following commands:
\begin{verbatim}
data.url <- "http://www.ditraglia.com/econ103/speed.csv"
speed <- read.csv(data.url, header = FALSE)
speed <- speed[,1]
\end{verbatim}
The second command is simply a quick way to tell R to store \texttt{speed} as a vector rather than a dataframe since it only contains one column.
\section*{Part II -- Additional Problems}

\begin{questions}

\question Oranges sold at Iovine Brothers Produce in Reading Terminal Market have weights that follow a normal distribution with a mean of 12 ounces and standard deviation of 2 ounces. 
	\begin{parts}
		\part If we choose an orange at random, what is the probability that it will weigh less than 10 ounces?
			\begin{solution}
<<>>=
pnorm(10, mean = 12, sd = 2)
@
			\end{solution}
		\part If we choose 25 oranges at random, what is the probability that they will have a total weight of less than 250 ounces?
			\begin{solution}
			Since the weight of any individual orange is an independent draw from a normal distribution with mean 12 ounces and standard deviation 2 ounces, the weight of \emph{25} oranges can be represented as a draw from a normal distribution with mean $25 \times 12 = 300$ and variance $25 \times 4 = 100$. Hence, the standard deviation is 10. Plugging this into R:
<<>>=
pnorm(250, mean = 300, sd = 10)
@
			\end{solution}
	\end{parts}

\question All other things equal, how would the following change the width of a confidence interval for the mean of a normal population? Explain.
	\begin{solution}
	All answers below are based on the following expression for a $(1-\alpha)\times 100\%$ confidence interval for the mean of a normal population when the population standard deviation is unknown:
		$$\bar{X}_n \pm \texttt{qt}(1 - \alpha/2, df = n-1) \times \frac{S}{\sqrt{n}}$$
		The width of this interval is
		$$\mbox{Width} = 2 \times \texttt{qt}(1 - \alpha/2, df = n-1) \times \frac{S}{\sqrt{n}}$$
	\end{solution}
	\begin{parts}
		\part The sample mean is smaller.
			\begin{solution}
				No effect: width doesn't involve the sample mean.
			\end{solution}
		\part The population mean is smaller.
			\begin{solution}
				No effect: width doesn't involve the population mean.
			\end{solution}
		\part The sample standard deviation is smaller.
			\begin{solution}
				If $S$ decreases, all other things constant, the width decreases.
			\end{solution}
		\part The sample size is smaller.
			\begin{solution}
			 Changing sample size has two effects but they both go in the same direction. First, if $n$ gets smaller, \texttt{qt}$(1 - \alpha/2, df = n-1)$ gets larger as we can see from the table presented in the lecture slides. Second, as $n$ gets smaller holding all other things fixed, $S/\sqrt{n}$ gets larger. Hence, decreasing sample size, all other things equal, increases the width.
			\end{solution}
	\end{parts}
	
\question Do you agree or disagree with the following statement: ``the household unemployment survey is hardly flawless; its 60,000 families constitute less than 0.1\% of the workforce.'' Explain your answer.
	\begin{solution}
	There may be flaws in the household unemployment survey, but the fact it is based on a sample of less than $0.1$\% of the workforce is not one of them. Sampling distributions only depend on the \emph{distribution} of the population, not on the \emph{number of individuals} that make up that population. As we saw in class, the variance of the sampling distribution of the sample mean is $\sigma^2/n$. Thus, the accuracy of the sample mean, in probabilistic terms, depends on the relative size of the \emph{population variance} versus the \emph{sample size}. It does \emph{not} depend on the relative size of the sample versus the population. 
	\end{solution}

\question Suppose you want to construct a 99\% confidence interval for the average height of US males above the age of 20. Based on past studies you think the standard deviation of heights for this population is around 6 inches. How large a sample should you gather to ensure that your confidence interval has a width no greater than 1 inch?
	\begin{solution}
		Assuming the population is normal and $\sigma$ is known, our confidence interval takes the form:
			$$\bar{X}_n \pm \texttt{qnorm}(1 - \alpha/2) \times \sigma/\sqrt{n}$$
		Thus, the width equals $2(1 - \alpha/2) \times \sigma/\sqrt{n}$. From the problem statement $\sigma = 6$. For a 99\% confidence interval we set $\alpha = 0.005$. Plugging this into R, we find \texttt{qnorm}$(1 - 0.01/2) \approx 2.58$. Thus, in terms of $n$, the width of our interval is approximately 
		$$ 2 \times 2.58 \times 6/\sqrt{n} \approx 31/\sqrt{n}$$
		Solving $1 = 31/\sqrt{n}$ for $n$ gives $n = 961$. Double checking this in R:
<<>>=
n <- 950:961
width <- 2 * qnorm(1 - 0.01/2) * 6/sqrt(n)
cbind(n, width)
@
so the exact answer is 956, which is pretty close to what we got using a rounded value for $2 \times \texttt{qnorm(1 - 0.01/2)} \times 6$ as we did above.
	\end{solution}

\question A well-known weekly news magazine once wrote that the width of a confidence interval is inversely related to sample size: for example, if a sample size of 500 gives a confidence interval of plus or minus 5, then a sample of 2500 would give a confidence interval of plus or minus 1. Explain the error in this argument.
	\begin{solution}
		This question involves symmetric confidence intervals, i.e.\ intervals of the form $\widehat{\theta} \pm ME$. As we have seen in class, the width of such intervals, whether based on the normal or t distributions, depends on $\sqrt{n}$ rather than $n$:
			\begin{eqnarray*}
			 \sigma \mbox{ Known:} \quad  \bar{X}_n &\pm&  \texttt{qnorm}(1 - \alpha/2) \times \frac{\sigma}{\sqrt{n}}\\
			\sigma \mbox{ Unknown:} \quad  \bar{X}_n &\pm& \texttt{qt}(1 - \alpha/2, df = n-1) \times \frac{S}{\sqrt{n}}
			\end{eqnarray*}
 Thus, all other things equal, we would have to quadruple the sample size to cut the width of the interval in half. (There is a slight complication that arises from the fact that the quantile of the $t$ interval also involves $n$, but as discussed in class, this only makes a practical difference in the confidence interval when $n$ is very small.)
	\end{solution}

\question This question uses the same data as question 8-9 from the textbook. (See above for instructions on how to download the data.) You may assume that the data constitute a random sample from a normal population.
  \begin{solution}
  First, read in the data and make sure they look reasonable:
<<>>=
speed.data <- read.csv("http://www.ditraglia.com/econ103/speed.csv", header = FALSE)
speed.data <- speed.data[,1]
head(speed.data)
@
  \end{solution}
	\begin{parts}
		\part Construct a 90\% confidence interval for population variance.
    \begin{solution}
<<>>=
n.speed <- length(speed.data)
a.speed <- qchisq(0.1/2, df = n.speed - 1)
b.speed <- qchisq(1 - 0.1/2, df = n.speed - 1)
LCL <- (n.speed - 1) * var(speed.data)/b.speed
UCL <- (n.speed - 1) * var(speed.data)/a.speed
c(LCL, UCL)
@
    \end{solution}
		\part The data for this problem are given in kilometers per hour. How would the confidence interval change if the data were expressed in miles per hour? Note that 1 km $\approx 0.62$ miles.
      \begin{solution}
      One way to solve this would be to convert the data to miles per hour and then repeat the above, noting that this will only change the sample variance so we can re-used everything else:
<<>>=
LCL.mhr <- (n.speed - 1) * var(0.62 * speed.data)/b.speed
UCL.mhr <- (n.speed - 1) * var(0.62 * speed.data)/a.speed
c(LCL.mhr, UCL.mhr)
@
  Another way would be to transform the confidence interval we have already created. From above:
    $$P(\Sexpr{round(LCL,2)} < \sigma^2 < \Sexpr{round(UCL,2)}) = 0.9$$
    where $\sigma^2$ has units (km/hr)$^2$. To transform to units of (miles/hr)$^2$ we need to multiply by (0.62 miles/km)$^2$. Notice that this leaves the meaning of the probability statement unchanged:
    $$P(\Sexpr{round(0.62^2 * LCL,2)} < 0.62^2 \times \sigma^2 < \Sexpr{round(0.62^2 * UCL,2)}) = 0.9$$
    Notice that this agrees with the alternative solution that we found by transforming the \emph{data} rather than the interval.
      \end{solution}
		\part Construct a 90\% confidence interval for the population \emph{standard deviation} in kilometers per hour.
      \begin{solution}
        To solve this, we use the fact that we can carry out algebraic manipulations within a probability statement without changing the meaning of that statement and hence the associated probability. (This is the logical equivalence rule). From above, we found a confidence interval
            $$P(\Sexpr{round(LCL,2)} < \sigma^2 < \Sexpr{round(UCL,2)}) = 0.9$$
        where the data are measured in km/hour. Taking square roots of everything:
        $$P(\Sexpr{round(sqrt(LCL),2)} < \sigma < \Sexpr{round(sqrt(UCL),2)}) = 0.9$$
      \end{solution}
	\end{parts}

\question Researchers asked a random sample of college students how many hours they sleep every night. The data are stored on my website and can be imported directly into R as follows:
\begin{verbatim}
data.url <- "http://www.ditraglia.com/econ103/sleep.csv"
sleep <- read.csv(data.url, header = FALSE)
sleep <- sleep[,1]
\end{verbatim}
The second command is simply a quick way to tell R to store \texttt{sleep} as a vector rather than a dataframe since it only contains one column. You may assume that the data represent a random sample from a normal population.
  \begin{solution}
  First, read in the data and make sure they look reasonable:
<<>>=
data.url <- "http://www.ditraglia.com/econ103/sleep.csv"
sleep.data <- read.csv(data.url, header = FALSE)
sleep.data <- sleep.data[,1]
head(sleep.data)
@
  \end{solution}
\begin{parts}
	\part Construct a 95\% confidence interval for the population mean.
  \begin{solution}
<<>>=
n.sleep <- length(sleep.data)
SE.sleep <- sd(sleep.data)/sqrt(n.sleep)
ME.sleep <- qt(1 - 0.05/2, df = n.sleep - 1) * SE.sleep
LCL <- mean(sleep.data) - ME.sleep
UCL <- mean(sleep.data) + ME.sleep
c(LCL, UCL)
@
  \end{solution}
	\part Construct a 95\% confidence interval for the population variance.
  \begin{solution}
<<>>=
a.sleep <- qchisq(0.05/2, df = n.sleep - 1)
b.sleep <- qchisq(1 - 0.05/2, df = n.sleep - 1)
LCL <- (n.sleep - 1) * var(sleep.data)/b.sleep
UCL <- (n.sleep - 1) * var(sleep.data)/a.sleep
c(LCL, UCL)
@
  \end{solution}
\end{parts}

\end{questions}


\end{document}